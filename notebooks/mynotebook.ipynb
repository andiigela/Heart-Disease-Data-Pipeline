{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/andig/Desktop/Punim Diplome/Heart-Disease-Data-Pipeline/data/raw/Heart_Disease_Mortality_Data_Among_US_Adults__35___by_State_Territory_and_County___2019-2021.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\n",
    "    'Year', 'LocationDesc', 'GeographicLevel', 'Topic', \n",
    "    'Data_Value', 'Data_Value_Unit', 'Data_Value_Type', \n",
    "    'StratificationCategory1', 'Stratification1', 'Y_lat', 'X_lon'\n",
    "]\n",
    "# Explanation for dropping these columns: \n",
    "    # LocationAbbr => There is another column for LocationDesc. You donâ€™t need both unless you're specifically using abbreviations.\n",
    "    # DataSource => Unless you are analyzing data from multiple sources and need to differentiate them, this column might not be critical for\n",
    "                        #  trend analysis.\n",
    "    # Class => It has only 1 unique value 'Cardiovascular Diseases' and we already know what the topic is.\n",
    "    # Data_Value_Footnote_Symbol => This is typically a reference to special notes or exceptions, which may not be relevant unless there are \n",
    "                        # specific footnote symbols you want to examine.\n",
    "    # Data_Value_Footnote => Similar to `Data_Value_Footnote_Symbol` column. Since we are simulating a data pipeline we do not need neither of\n",
    "                        #  these 2 columns.\n",
    "    # StratificationCategory2 => These columns represent secondary stratifications (e.g., a second demographic category like ethnicity), \n",
    "                        #           which we do not need because our focuse is on a single dimension such as age or gender \n",
    "                        #           from StratificationCategory1 and Stratification1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Race/Ethnicity'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"StratificationCategory2\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the percentage of missing values in the Data_Value column. If a large proportion of your data (e.g., more than 20-30%) is missing,\n",
    "#  you may want to consider filling them.\n",
    "# - Around 56.33% data loss after dropna() so we are deciding to fill values and not drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns with na values:\n",
    "    # Data_Value => 44362 \n",
    "    # Y_lat => 24\n",
    "    # X_lon => 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The median is a better choice for skewed distributions because it is not affected by outliers and gives a better \n",
    "# sense of the central tendency for non-symmetrical data.\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df_filtered['Data_Value'], bins=30, kde=True)\n",
    "plt.title('Distribution of Data_Value')\n",
    "plt.show()\n",
    "# Data_Value Fillna Method => median\n",
    "df_filtered['Data_Value'] = df_filtered['Data_Value'].fillna(df_filtered['Data_Value'].median()) # fill_na for Data_Value with mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        60.193263\n",
       "1        33.810226\n",
       "2        33.716065\n",
       "3        35.005864\n",
       "4       -14.301754\n",
       "           ...    \n",
       "78787    31.302471\n",
       "78788    44.852965\n",
       "78789    43.578585\n",
       "78790    30.797847\n",
       "78791    36.684847\n",
       "Name: Y_lat, Length: 78792, dtype: float64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
