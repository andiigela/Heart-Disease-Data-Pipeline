{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/andig/Desktop/Punim Diplome/Heart-Disease-Data-Pipeline/data/raw/Heart_Disease_Mortality_Data_Among_US_Adults__35___by_State_Territory_and_County___2019-2021.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\n",
    "    'Year', 'LocationDesc', 'GeographicLevel', 'Topic', \n",
    "    'Data_Value', 'Data_Value_Unit', 'Data_Value_Type', \n",
    "    'StratificationCategory1', 'Stratification1', 'Y_lat', 'X_lon'\n",
    "]\n",
    "# Explanation for dropping these columns: \n",
    "    # LocationAbbr => There is another column for LocationDesc. You donâ€™t need both unless you're specifically using abbreviations.\n",
    "    # DataSource => Unless you are analyzing data from multiple sources and need to differentiate them, this column might not be critical for\n",
    "                        #  trend analysis.\n",
    "    # Class => It has only 1 unique value 'Cardiovascular Diseases' and we already know what the topic is.\n",
    "    # Data_Value_Footnote_Symbol => This is typically a reference to special notes or exceptions, which may not be relevant unless there are \n",
    "                        # specific footnote symbols you want to examine.\n",
    "    # Data_Value_Footnote => Similar to `Data_Value_Footnote_Symbol` column. Since we are simulating a data pipeline we do not need neither of\n",
    "                        #  these 2 columns.\n",
    "    # StratificationCategory2 => These columns represent secondary stratifications (e.g., a second demographic category like ethnicity), \n",
    "                        #           which we do not need because our focuse is on a single dimension such as age or gender \n",
    "                        #           from StratificationCategory1 and Stratification1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Race/Ethnicity'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"StratificationCategory2\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the percentage of missing values in the Data_Value column. If a large proportion of your data (e.g., more than 20-30%) is missing,\n",
    "#  you may want to consider filling them.\n",
    "# - Around 56.33% data loss after dropna() so we are deciding to fill values and not drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns with na values:\n",
    "    # Data_Value => 44362 \n",
    "    # Y_lat => 24\n",
    "    # X_lon => 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The median is a better choice for skewed distributions because it is not affected by outliers and gives a better \n",
    "# sense of the central tendency for non-symmetrical data.\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df_filtered['Data_Value'], bins=30, kde=True)\n",
    "plt.title('Distribution of Data_Value')\n",
    "plt.show()\n",
    "# Since Data_Value is Right skewed we choose fillna method => median\n",
    "df_filtered['Data_Value'] = df_filtered['Data_Value'].fillna(df_filtered['Data_Value'].median()) # fill_na for Data_Value with mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0392245022794095\n"
     ]
    }
   ],
   "source": [
    "data_value_skewness = df_filtered['Data_Value'].skew()\n",
    "print(data_value_skewness) # Moderate right skew even after fillna method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.dropna(inplace=True) # we are dropping since only 48 rows are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
